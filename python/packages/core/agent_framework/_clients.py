# Copyright (c) Microsoft. All rights reserved.

import asyncio
import sys
from abc import ABC, abstractmethod
from collections.abc import (
    AsyncIterable,
    Callable,
    Mapping,
    MutableMapping,
    MutableSequence,
    Sequence,
)
from typing import (
    TYPE_CHECKING,
    Any,
    ClassVar,
    Generic,
    Protocol,
    TypedDict,
    cast,
    overload,
    runtime_checkable,
)

from pydantic import BaseModel

from ._logging import get_logger
from ._memory import ContextProvider
from ._middleware import (
    ChatMiddleware,
    ChatMiddlewareCallable,
    FunctionMiddleware,
    FunctionMiddlewareCallable,
    Middleware,
)
from ._serialization import SerializationMixin
from ._threads import ChatMessageStoreProtocol
from ._tools import (
    FUNCTION_INVOKING_CHAT_CLIENT_MARKER,
    FunctionInvocationConfiguration,
    ToolProtocol,
)
from ._types import (
    ChatMessage,
    ChatResponse,
    ChatResponseUpdate,
    prepare_messages,
    validate_chat_options,
)

if sys.version_info >= (3, 13):
    from typing import TypeVar  # type: ignore # pragma: no cover
else:
    from typing_extensions import TypeVar  # type: ignore # pragma: no cover


if TYPE_CHECKING:
    from ._agents import ChatAgent
    from ._types import ChatOptions


TInput = TypeVar("TInput", contravariant=True)
TEmbedding = TypeVar("TEmbedding")
TBaseChatClient = TypeVar("TBaseChatClient", bound="BaseChatClient")

logger = get_logger()

__all__ = [
    "BaseChatClient",
    "ChatClientProtocol",
]


# region ChatClientProtocol Protocol

# Contravariant for the Protocol
TOptions_contra = TypeVar(
    "TOptions_contra",
    bound=TypedDict,  # type: ignore[valid-type]
    default="ChatOptions",
    contravariant=True,
)


@runtime_checkable
class ChatClientProtocol(Protocol[TOptions_contra]):  #
    """A protocol for a chat client that can generate responses.

    This protocol defines the interface that all chat clients must implement,
    including methods for generating both streaming and non-streaming responses.

    The generic type parameter TOptions specifies which options TypedDict this
    client accepts, enabling IDE autocomplete and type checking for provider-specific
    options.

    Note:
        Protocols use structural subtyping (duck typing). Classes don't need
        to explicitly inherit from this protocol to be considered compatible.

    Examples:
        .. code-block:: python

            from agent_framework import ChatClientProtocol, ChatResponse, ChatMessage


            # Any class implementing the required methods is compatible
            class CustomChatClient:
                async def get_response(self, messages, **kwargs):
                    # Your custom implementation
                    return ChatResponse(messages=[], response_id="custom")

                def get_streaming_response(self, messages, **kwargs):
                    async def _stream():
                        from agent_framework import ChatResponseUpdate

                        yield ChatResponseUpdate()

                    return _stream()


            # Verify the instance satisfies the protocol
            client = CustomChatClient()
            assert isinstance(client, ChatClientProtocol)
    """

    additional_properties: dict[str, Any]

    @overload
    async def get_response(
        self,
        messages: str | ChatMessage | Sequence[str | ChatMessage],
        *,
        options: "ChatOptions[TResponseModelT]",
        **kwargs: Any,
    ) -> "ChatResponse[TResponseModelT]": ...

    @overload
    async def get_response(
        self,
        messages: str | ChatMessage | Sequence[str | ChatMessage],
        *,
        options: TOptions_contra | None = None,
        **kwargs: Any,
    ) -> ChatResponse:
        """Send input and return the response.

        Args:
            messages: The sequence of input messages to send.
            options: Chat options as a TypedDict.
            **kwargs: Additional chat options.

        Returns:
            The response messages generated by the client.

        Raises:
            ValueError: If the input message sequence is ``None``.
        """
        ...

    def get_streaming_response(
        self,
        messages: str | ChatMessage | Sequence[str | ChatMessage],
        *,
        options: TOptions_contra | None = None,
        **kwargs: Any,
    ) -> AsyncIterable[ChatResponseUpdate]:
        """Send input messages and stream the response.

        Args:
            messages: The sequence of input messages to send.
            options: Chat options as a TypedDict.
            **kwargs: Additional chat options.

        Yields:
            ChatResponseUpdate: Partial response updates as they're generated.
        """
        ...


# endregion


# region ChatClientBase

# Covariant for the BaseChatClient
TOptions_co = TypeVar(
    "TOptions_co",
    bound=TypedDict,  # type: ignore[valid-type]
    default="ChatOptions",
    covariant=True,
)

TResponseModel = TypeVar("TResponseModel", bound=BaseModel | None, default=None, covariant=True)
TResponseModelT = TypeVar("TResponseModelT", bound=BaseModel)


class BaseChatClient(SerializationMixin, ABC, Generic[TOptions_co]):
    """Base class for chat clients.

    This abstract base class provides core functionality for chat client implementations,
    including middleware support, message preparation, and tool normalization.

    The generic type parameter TOptions specifies which options TypedDict this client
    accepts. This enables IDE autocomplete and type checking for provider-specific options
    when using the typed overloads of get_response and get_streaming_response.

    Note:
        BaseChatClient cannot be instantiated directly as it's an abstract base class.
        Subclasses must implement ``_inner_get_response()`` and ``_inner_get_streaming_response()``.

    Examples:
        .. code-block:: python

            from agent_framework import BaseChatClient, ChatResponse, ChatMessage
            from collections.abc import AsyncIterable


            class CustomChatClient(BaseChatClient):
                async def _inner_get_response(self, *, messages, options, **kwargs):
                    # Your custom implementation
                    return ChatResponse(
                        messages=[ChatMessage(role="assistant", text="Hello!")], response_id="custom-response"
                    )

                async def _inner_get_streaming_response(self, *, messages, options, **kwargs):
                    # Your custom streaming implementation
                    from agent_framework import ChatResponseUpdate

                    yield ChatResponseUpdate(role="assistant", contents=[{"type": "text", "text": "Hello!"}])


            # Create an instance of your custom client
            client = CustomChatClient()

            # Use the client to get responses
            response = await client.get_response("Hello, how are you?")
    """

    OTEL_PROVIDER_NAME: ClassVar[str] = "unknown"
    DEFAULT_EXCLUDE: ClassVar[set[str]] = {"additional_properties"}
    # This is used for OTel setup, should be overridden in subclasses

    def __init__(
        self,
        *,
        middleware: (
            Sequence[ChatMiddleware | ChatMiddlewareCallable | FunctionMiddleware | FunctionMiddlewareCallable] | None
        ) = None,
        additional_properties: dict[str, Any] | None = None,
        **kwargs: Any,
    ) -> None:
        """Initialize a BaseChatClient instance.

        Keyword Args:
            middleware: Middleware for the client.
            additional_properties: Additional properties for the client.
            kwargs: Additional keyword arguments (merged into additional_properties).
        """
        # Merge kwargs into additional_properties
        self.additional_properties = additional_properties or {}
        self.additional_properties.update(kwargs)

        self.middleware = middleware

        self.function_invocation_configuration = (
            FunctionInvocationConfiguration() if hasattr(self.__class__, FUNCTION_INVOKING_CHAT_CLIENT_MARKER) else None
        )

    def to_dict(self, *, exclude: set[str] | None = None, exclude_none: bool = True) -> dict[str, Any]:
        """Convert the instance to a dictionary.

        Extracts additional_properties fields to the root level.

        Keyword Args:
            exclude: Set of field names to exclude from serialization.
            exclude_none: Whether to exclude None values from the output. Defaults to True.

        Returns:
            Dictionary representation of the instance.
        """
        # Get the base dict from SerializationMixin
        result = super().to_dict(exclude=exclude, exclude_none=exclude_none)

        # Extract additional_properties to root level
        if self.additional_properties:
            result.update(self.additional_properties)

        return result

    # region Internal methods to be implemented by the derived classes

    @abstractmethod
    async def _inner_get_response(
        self,
        *,
        messages: MutableSequence[ChatMessage],
        options: dict[str, Any],
        **kwargs: Any,
    ) -> ChatResponse:
        """Send a chat request to the AI service.

        Keyword Args:
            messages: The chat messages to send.
            options: The options dict for the request.
            kwargs: Any additional keyword arguments.

        Returns:
            The chat response contents representing the response(s).
        """

    @abstractmethod
    async def _inner_get_streaming_response(
        self,
        *,
        messages: MutableSequence[ChatMessage],
        options: dict[str, Any],
        **kwargs: Any,
    ) -> AsyncIterable[ChatResponseUpdate]:
        """Send a streaming chat request to the AI service.

        Keyword Args:
            messages: The chat messages to send.
            options: The options dict for the request.
            kwargs: Any additional keyword arguments.

        Yields:
            ChatResponseUpdate: The streaming chat message contents.
        """
        # Below is needed for mypy: https://mypy.readthedocs.io/en/stable/more_types.html#asynchronous-iterators
        if False:
            yield
        await asyncio.sleep(0)  # pragma: no cover
        # This is a no-op, but it allows the method to be async and return an AsyncIterable.
        # The actual implementation should yield ChatResponseUpdate instances as needed.

    # endregion

    # region Public method

    @overload
    async def get_response(
        self,
        messages: str | ChatMessage | Sequence[str | ChatMessage],
        *,
        options: "ChatOptions[TResponseModelT]",
        **kwargs: Any,
    ) -> ChatResponse[TResponseModelT]: ...

    @overload
    async def get_response(
        self,
        messages: str | ChatMessage | Sequence[str | ChatMessage],
        *,
        options: TOptions_co | None = None,
        **kwargs: Any,
    ) -> ChatResponse: ...

    async def get_response(
        self,
        messages: str | ChatMessage | Sequence[str | ChatMessage],
        *,
        options: TOptions_co | "ChatOptions[Any]" | None = None,
        **kwargs: Any,
    ) -> ChatResponse[Any]:
        """Get a response from a chat client.

        Args:
            messages: The message or messages to send to the model.
            options: Chat options as a TypedDict.
            **kwargs: Other keyword arguments, can be used to pass function specific parameters.

        Returns:
            A chat response from the model.
        """
        return await self._inner_get_response(
            messages=prepare_messages(messages),
            options=await validate_chat_options(dict(options) if options else {}),
            **kwargs,
        )

    async def get_streaming_response(
        self,
        messages: str | ChatMessage | Sequence[str | ChatMessage],
        *,
        options: TOptions_co | None = None,
        **kwargs: Any,
    ) -> AsyncIterable[ChatResponseUpdate]:
        """Get a streaming response from a chat client.

        Args:
            messages: The message or messages to send to the model.
            options: Chat options as a TypedDict.
            **kwargs: Other keyword arguments, can be used to pass function specific parameters.

        Yields:
            ChatResponseUpdate: A stream representing the response(s) from the LLM.
        """
        async for update in self._inner_get_streaming_response(
            messages=prepare_messages(messages),
            options=await validate_chat_options(dict(options) if options else {}),
            **kwargs,
        ):
            yield update

    def service_url(self) -> str:
        """Get the URL of the service.

        Override this in the subclass to return the proper URL.
        If the service does not have a URL, return None.

        Returns:
            The service URL or 'Unknown' if not implemented.
        """
        return "Unknown"

    def as_agent(
        self,
        *,
        id: str | None = None,
        name: str | None = None,
        description: str | None = None,
        instructions: str | None = None,
        tools: ToolProtocol
        | Callable[..., Any]
        | MutableMapping[str, Any]
        | Sequence[ToolProtocol | Callable[..., Any] | MutableMapping[str, Any]]
        | None = None,
        default_options: TOptions_co | Mapping[str, Any] | None = None,
        chat_message_store_factory: Callable[[], ChatMessageStoreProtocol] | None = None,
        context_provider: ContextProvider | None = None,
        middleware: Sequence[Middleware] | None = None,
        **kwargs: Any,
    ) -> "ChatAgent[TOptions_co]":
        """Create a ChatAgent with this client.

        This is a convenience method that creates a ChatAgent instance with this
        chat client already configured.

        Keyword Args:
            id: The unique identifier for the agent. Will be created automatically if not provided.
            name: The name of the agent.
            description: A brief description of the agent's purpose.
            instructions: Optional instructions for the agent.
                These will be put into the messages sent to the chat client service as a system message.
            tools: The tools to use for the request.
            default_options: A TypedDict containing chat options. When using a typed client like
                ``OpenAIChatClient``, this enables IDE autocomplete for provider-specific options
                including temperature, max_tokens, model_id, tool_choice, and more.
                Note: response_format typing does not flow into run outputs when set via default_options,
                and dict literals are accepted without specialized option typing.
            chat_message_store_factory: Factory function to create an instance of ChatMessageStoreProtocol.
                If not provided, the default in-memory store will be used.
            context_provider: Context providers to include during agent invocation.
            middleware: List of middleware to intercept agent and function invocations.
            kwargs: Any additional keyword arguments. Will be stored as ``additional_properties``.

        Returns:
            A ChatAgent instance configured with this chat client.

        Examples:
            .. code-block:: python

                from agent_framework.openai import OpenAIChatClient

                # Create a client
                client = OpenAIChatClient(model_id="gpt-4")

                # Create an agent using the convenience method
                agent = client.as_agent(
                    name="assistant",
                    instructions="You are a helpful assistant.",
                    default_options={"temperature": 0.7, "max_tokens": 500},
                )

                # Run the agent
                response = await agent.run("Hello!")
        """
        from ._agents import ChatAgent

        return ChatAgent(
            chat_client=self,
            id=id,
            name=name,
            description=description,
            instructions=instructions,
            tools=tools,
            default_options=cast(Any, default_options),
            chat_message_store_factory=chat_message_store_factory,
            context_provider=context_provider,
            middleware=middleware,
            **kwargs,
        )
